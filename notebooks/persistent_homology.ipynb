{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "import sys, os\n",
    "sys.path.insert(0, '../')\n",
    "sys.path.insert(0, '../python_src/')\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import scipy as sp\n",
    "import scipy.io as spio\n",
    "\n",
    "import matplotlib.pyplot as plt; plt.rcdefaults()\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import itertools as it\n",
    "import collections as co\n",
    "import queue\n",
    "import networkx as nx\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "from skimage import filters as skifilters\n",
    "from skimage import color as skicolor\n",
    "\n",
    "from sklearn import linear_model\n",
    "\n",
    "import homology\n",
    "\n",
    "mpl.rcParams['mathtext.fontset'] = 'cm'\n",
    "sns.set_context('poster', font_scale=1.25)\n",
    "sns.set(color_codes=True, palette='deep')\n",
    "sns.set_style('ticks', {'xtick.direction': 'in','ytick.direction': 'in', 'axes.linewidth': 2.0})\n",
    "\n",
    "\n",
    "\n",
    "def total_size(o, handlers={}, verbose=False):\n",
    "    \"\"\" Returns the approximate memory footprint an object and all of its contents.\n",
    "\n",
    "    Automatically finds the contents of the following builtin containers and\n",
    "    their subclasses:  tuple, list, deque, dict, set and frozenset.\n",
    "    To search other containers, add handlers to iterate over their contents:\n",
    "\n",
    "        handlers = {SomeContainerClass: iter,\n",
    "                    OtherContainerClass: OtherContainerClass.get_elements}\n",
    "\n",
    "    \"\"\"\n",
    "    dict_handler = lambda d: it.chain.from_iterable(d.items())\n",
    "    all_handlers = {tuple: iter,\n",
    "                    list: iter,\n",
    "                    co.deque: iter,\n",
    "                    dict: dict_handler,\n",
    "                    set: iter,\n",
    "                    frozenset: iter,\n",
    "                   }\n",
    "    all_handlers.update(handlers)     # user handlers take precedence\n",
    "    seen = set()                      # track which object id's have already been seen\n",
    "    default_size = sys.getsizeof(0)       # estimate sizeof object without __sizeof__\n",
    "\n",
    "    def sizeof(o):\n",
    "        if id(o) in seen:       # do not double count the same object\n",
    "            return 0\n",
    "        seen.add(id(o))\n",
    "        s = sys.getsizeof(o, default_size)\n",
    "\n",
    "        if verbose:\n",
    "            print(s, type(o), repr(o), file=sys.stderr)\n",
    "\n",
    "        for typ, handler in all_handlers.items():\n",
    "            if isinstance(o, typ):\n",
    "                s += sum(map(sizeof, handler(o)))\n",
    "                break\n",
    "                \n",
    "                \n",
    "        if not hasattr(o.__class__, '__slots__'):\n",
    "            if hasattr(o, '__dict__'):\n",
    "                s+=sizeof(o.__dict__) # no __slots__ *usually* means a __dict__, but some special builtin classes (such as `type(None)`) have neither\n",
    "            # else, `o` has no attributes at all, so sys.getsizeof() actually returned the correct value\n",
    "        else:\n",
    "            s+=sum(sizeof(getattr(o, x)) for x in o.__class__.__slots__ if hasattr(o, x))\n",
    "                   \n",
    "        \n",
    "        return s\n",
    "    \n",
    "    return sizeof(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "label = 'Z16'\n",
    "\n",
    "# mat = spio.loadmat(\"../sample_data/{}.mat\".format(label))\n",
    "# data = mat[label][500:2500, 500:2500]\n",
    "\n",
    "mat = spio.loadmat(\"Everest.mat\")\n",
    "data = mat['Expression1']\n",
    "\n",
    "print(total_size(mat))\n",
    "\n",
    "# dx = 5280 * data.shape[0] / 20\n",
    "# dy = 5280 * data.shape[1] / 20\n",
    "\n",
    "# data = mpimg.imread('2D6185C9-1DD8-B71C-076FF6978423E103-large.jpg')[:,:,:3]\n",
    "# data = mpimg.imread('20170105_100151.jpg')[:,:,:3]\n",
    "# # data = mpimg.imread('2018-01-12.png')[:,:,:3]\n",
    "\n",
    "# data = skicolor.rgb2gray(data)\n",
    "# data = skifilters.laplace(data)\n",
    "\n",
    "# data = np.zeros([100, 100], float)\n",
    "# data[50, 50] = -1\n",
    "\n",
    "# print(np.min(data), np.max(data))\n",
    "\n",
    "\n",
    "# data = np.array([[10, 0, 10],\n",
    "#                 [2, 1, 2],                        \n",
    "#                 [3, 6, 3],\n",
    "#                 [4, 5, 4]])\n",
    "\n",
    "# data = np.array([[3,2,2],\n",
    "#                 [3,1,1],\n",
    "#                 [0,1,0]])\n",
    "\n",
    "# data = np.array([[8, 3, 2],\n",
    "#                 [7, 8, 1],\n",
    "#                 [6, 9, 1],\n",
    "#                 [5, 10, 0]])\n",
    "\n",
    "\n",
    "print(data.shape)\n",
    "\n",
    "ls = mcolors.LightSource()\n",
    "\n",
    "# norm = mpl.colors.Normalize(vmin=np.min(data),vmax=np.max(data))\n",
    "norm = mpl.colors.Normalize(vmin=0,vmax=1)\n",
    "smap = cm.ScalarMappable(norm=norm, cmap=plt.cm.Greys_r)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16,16))\n",
    "# im = ax.imshow(smap.to_rgba(data))\n",
    "\n",
    "image = smap.to_rgba(ls.hillshade(data, vert_exag=100, dx=1, dy=1)).reshape([data.shape[0]*data.shape[1], 4])\n",
    "\n",
    "h = \"ff7f00\"\n",
    "color = list(int(h[i:i+2], 16) / 256.0 for i in (0, 2 ,4))\n",
    "color.append(1)\n",
    "image[np.where(np.isnan(data.flatten()))[0]] = color\n",
    "im = ax.imshow(image.reshape([data.shape[0], data.shape[1], 4]))\n",
    "\n",
    "\n",
    "# ax.hlines(np.linspace(int(data.shape[0]/3), 2*int(data.shape[0]/3), 2), 0, data.shape[1])\n",
    "# ax.vlines(np.linspace(int(data.shape[1]/3), 2*int(data.shape[1]/3), 2), 0, data.shape[0])\n",
    "\n",
    "\n",
    "ax.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# X = 1\n",
    "# Y = 1\n",
    "\n",
    "# data = data[Y*int(data.shape[0]/2):(Y+1)*int(data.shape[0]/2), \n",
    "#             X*int(data.shape[1]/2):(X+1)*int(data.shape[1]/2)]\n",
    "\n",
    "# print(data.shape)\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(16,16))\n",
    "# im = ax.imshow(smap.to_rgba(ls.hillshade(data, vert_exag=100, dx=1, dy=1)))\n",
    "\n",
    "# ax.axis('off')\n",
    "# plt.show()\n",
    "# print(total_size(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "dual = True\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "print(\"Constructing complex\")\n",
    "comp = homology.construct_cubical_complex(data.shape, oriented=False, dual=dual)\n",
    "\n",
    "# for c in comp.get_cells():\n",
    "#     print(c, comp.get_dim(c), comp.get_facets(c))\n",
    "\n",
    "print(\"Checking boundary operator\")\n",
    "print(homology.check_boundary_op(comp))\n",
    "\n",
    "print(\"Constructing cofacets\")\n",
    "comp.construct_cofacets()\n",
    "\n",
    "# for c in comp.get_cells():\n",
    "#     print(c, comp.get_dim(c), comp.get_cofacets(c))\n",
    "\n",
    "print(total_size(comp))\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Elapsed Time:\", end - start)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "print(\"Finding vertex order\")\n",
    "\n",
    "vertex_time = data.flatten()\n",
    "vertex_order = homology.construct_vertex_filtration_order(comp, vertex_time, euclidean=False, positions=None)\n",
    "\n",
    "print(total_size(vertex_time))\n",
    "print(total_size(vertex_order))\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Elapsed Time:\", end - start)\n",
    "\n",
    "# print(vertex_order)\n",
    "\n",
    "# # fig, ax = plt.subplots(figsize=(16,16))\n",
    "# # im = ax.imshow(vertex_order.reshape(data.shape), cmap=plt.cm.Greys_r)\n",
    "\n",
    "# # ax.axis('off')\n",
    "# # # plt.colorbar(im)\n",
    "# # plt.show()\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "print(\"Finding Insertion Times\")\n",
    "\n",
    "insert_order = homology.construct_time_of_insertion_map(comp, vertex_time, vertex_order, dual=dual)\n",
    "\n",
    "print(total_size(insert_order))\n",
    "\n",
    "# print(insert_order)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Elapsed Time:\", end - start)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "print(\"Constructing discrete gradient\")\n",
    "\n",
    "V = homology.construct_discrete_gradient(comp, insert_order, dual=dual)\n",
    "\n",
    "print(total_size(V))\n",
    "\n",
    "# print(V)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Elapsed Time:\", end - start)\n",
    "\n",
    "n = 0\n",
    "for v in range(len(V)):\n",
    "#     print(v, V[v])\n",
    "    \n",
    "    if V[v] == v:\n",
    "        n += 1\n",
    "        \n",
    "\n",
    "print(\"Number Critical Cells:\", n)\n",
    "\n",
    "print(\"Reversing gradient\")\n",
    "coV = homology.reverse_discrete_gradient(V)\n",
    "\n",
    "print(total_size(coV))\n",
    "\n",
    "# # print(V)\n",
    "# # print(coV)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "print(\"Calculating Morse complex\")\n",
    "mcomp = homology.construct_morse_complex(V, comp, oriented=False)\n",
    "\n",
    "print(\"Checking boundary operator\")\n",
    "print(homology.check_boundary_op(mcomp))\n",
    "\n",
    "print(\"Constructing cofacets\")\n",
    "mcomp.construct_cofacets()\n",
    "\n",
    "\n",
    "\n",
    "# for c in mcomp.get_cells():\n",
    "#     print(c, mcomp.get_dim(c), mcomp.get_facets(c), mcomp.get_coeffs(c))\n",
    "# for c in mcomp.get_cells():\n",
    "#     print(c, mcomp.get_dim(c), mcomp.get_cofacets(c))\n",
    "\n",
    "print(total_size(mcomp))\n",
    "\n",
    "end = time.time()\n",
    "print(\"Elapsed Time:\", end - start)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "print(\"Finding basins\")\n",
    "basins = homology.find_basins(mcomp, coV, comp, insert_order, dual=dual)\n",
    "# print(basins)\n",
    "\n",
    "print(total_size(basins))\n",
    "\n",
    "print(\"Calculating Morse skeleton\")\n",
    "skeleton = homology.find_morse_skeleton(mcomp, V, comp, 1, insert_order, dual=dual)\n",
    "\n",
    "print(total_size(skeleton))\n",
    "\n",
    "end = time.time()\n",
    "print(\"Elapsed Time:\", end - start)\n",
    "\n",
    "\n",
    "palette1 = it.cycle(sns.color_palette(\"deep\"))\n",
    "palette2 = it.cycle(['Blues_r', 'Greens_r', 'Purples_r', 'Oranges_r', 'RdPu_r'])\n",
    "\n",
    "basin_color_map1 = {}\n",
    "basin_color_map2 = {}\n",
    "for v in basins:\n",
    "# for v in mcomp.get_cells():\n",
    "#     if mcomp.dims[v]== 0:\n",
    "    basin_color_map1[v] = next(palette1)\n",
    "    basin_color_map2[v] = next(palette2)\n",
    "\n",
    "print(\"Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "print(\"Simplifying Morse Complex\")\n",
    "\n",
    "V, coV = homology.simplify_morse_complex(2e-2, V, coV, comp, insert_order)\n",
    "\n",
    "n = 0\n",
    "for v in V:\n",
    "    if v == V[v]:\n",
    "#         print(v, comp.dims[v])\n",
    "        n += 1\n",
    "\n",
    "print(\"Calculating Morse complex\")\n",
    "mcomp = homology.construct_morse_complex(V, comp, oriented=False)\n",
    "\n",
    "print(\"Checking Boundary Operator\")\n",
    "print(homology.check_boundary_op(comp))\n",
    "\n",
    "mcomp.construct_cofacets()\n",
    "    \n",
    "print(\"Finding basins\")\n",
    "basins = homology.find_basins(mcomp, coV, comp, insert_order, dual=dual)    \n",
    "    \n",
    "print(\"Calculating Morse skeleton\")\n",
    "skeleton = homology.find_morse_skeleton(mcomp, V, comp, 1, insert_order, dual=dual)\n",
    "\n",
    "    \n",
    "print(\"Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "\n",
    "# image = np.ones([data.shape[0]*data.shape[1], 3])\n",
    "\n",
    "# for i in basins:\n",
    "#     image[list(basins[i])] = basin_color_map1[i]\n",
    "    \n",
    "# image[list(skeleton)] = (0.0, 0.0, 0.0)\n",
    "\n",
    "# # for i in basins:\n",
    "# #     image[i] = (1.0, 1.0, 1.0)\n",
    "        \n",
    "# print(np.min(data), np.max(data))\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(16, 16))\n",
    "# ax.imshow(image.reshape((data.shape[0], data.shape[1], 3)))\n",
    "# ax.axis('off')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "\n",
    "image = np.zeros([data.shape[0]*data.shape[1], 4])   \n",
    "\n",
    "ls = mcolors.LightSource()\n",
    "shaded = ls.hillshade(data, vert_exag=100, dx=1, dy=1).flatten()\n",
    "\n",
    "for i in basins:\n",
    "    \n",
    "#     norm = mpl.colors.Normalize(vmin=np.min(data), vmax=np.max(data))\n",
    "#     smap = cm.ScalarMappable(norm=norm, cmap=basin_color_map2[i])\n",
    "#     image[list(basins[i])] = smap.to_rgba(vertex_time[list(basins[i])])\n",
    "    \n",
    "    norm = mpl.colors.Normalize(vmin=0, vmax=1)\n",
    "    smap = cm.ScalarMappable(norm=norm, cmap=basin_color_map2[i])\n",
    "    image[list(basins[i])] = smap.to_rgba(shaded[list(basins[i])])\n",
    "    \n",
    "\n",
    "image[list(skeleton)] = (0.0, 0.0, 0.0, 1.0)\n",
    "\n",
    "for i in basins:\n",
    "    image[i] = (1.0, 1.0, 1.0, 1.0)\n",
    "        \n",
    "print(np.min(data), np.max(data))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 16))\n",
    "ax.imshow(image.reshape((data.shape[0], data.shape[1], 4)))\n",
    "ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "print(\"Calculating persistence pairs...\")\n",
    "\n",
    "filtration = homology.construct_filtration(mcomp, insert_order)\n",
    "\n",
    "# weights = homology.get_morse_weights(mcomp, V, coV, comp.facets, comp.cofacets)\n",
    "   \n",
    "# print(\"Weights:\", weights)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "pairs = homology.compute_persistence(mcomp, filtration)\n",
    "# (pairs, bcycles) = homology.compute_persistence(mcomp, filtration, \n",
    "#                                                             birth_cycles=True, optimal_cycles=False)\n",
    "# (pairs, bcycles, ocycles) = homology.compute_persistence(mcomp, filtration, \n",
    "#                                                             birth_cycles=True, optimal_cycles=True,\n",
    "#                                                                     weights=weights, relative_cycles=True)\n",
    "\n",
    "print(\"Number Pairs:\", len(pairs))\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Elapsed Time:\", end - start)\n",
    "\n",
    "# print(\"Pairs:\", pairs)\n",
    "# print(\"Birth Cycles:\", bcycles)\n",
    "# print(\"Death Cycles:\", ocycles)\n",
    "        \n",
    "print(\"Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "TIME = 0\n",
    "\n",
    "birth = [[] for i in range(mcomp.dim+1)]\n",
    "death = [[] for i in range(mcomp.dim+1)]\n",
    "\n",
    "for (i, j) in pairs:\n",
    "    \n",
    "    d = mcomp.get_dim(i)\n",
    "    birth[d].append(insert_order[i][TIME])\n",
    "    if j is not None:\n",
    "        death[d].append(insert_order[j][TIME])\n",
    "    else:\n",
    "        death[d].append(insert_order[i][TIME])\n",
    "    \n",
    "fig = plt.figure(figsize=(8,8))\n",
    "    \n",
    "ax1 = fig.add_subplot(1,1,1)\n",
    "\n",
    "ax1.scatter(birth[0], death[0], marker='.', color='b', label=\"$0$-cycles\")\n",
    "ax1.scatter(death[1], birth[1], marker='.', color='r', label=\"$1$-cycles\")\n",
    "\n",
    "ax1.plot(np.linspace(np.min(vertex_time), np.max(vertex_time), 100), np.linspace(np.min(vertex_time), np.max(vertex_time), 100), 'k--')\n",
    "\n",
    "ax1.set_title(r\"$d={}$\".format(0))\n",
    "\n",
    "ax1.set_xlabel(r\"Birth [height]\")\n",
    "ax1.set_ylabel(r\"Death [height]\")\n",
    "\n",
    "ax1.legend(fontsize='large')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "TIME = 0\n",
    "\n",
    "birth = [[] for i in range(mcomp.dim+1)]\n",
    "persistence = [[] for i in range(mcomp.dim+1)]\n",
    "\n",
    "for (i, j) in pairs:\n",
    "    \n",
    "    if j is None or insert_order[i][TIME] == insert_order[j][TIME]:\n",
    "        continue\n",
    "        \n",
    "    \n",
    "    \n",
    "    d = mcomp.get_dim(i)\n",
    "    birth[d].append(insert_order[i][TIME])\n",
    "    persistence[d].append(insert_order[j][TIME]-insert_order[i][TIME])\n",
    "\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "        \n",
    "ax1 = fig.add_subplot(1,1,1)\n",
    "\n",
    "ax1.set_yscale('log')\n",
    "\n",
    "ax1.scatter(birth[0], persistence[0], marker='.', color='b', label=\"$0$-cycles\")\n",
    "ax1.scatter(birth[1], persistence[1], marker='.', color='r', label=\"$1$-cycles\")\n",
    "\n",
    "ax1.set_xlabel(r\"Birth [height]\")\n",
    "ax1.set_ylabel(r\"Persistence [height]\")\n",
    "# ax1.set_ylim(1e-8, 1e0)\n",
    "\n",
    "# ax1.hlines(10**(-1.9), -0.4, 1.0)\n",
    "\n",
    "ax1.legend(fontsize='large')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "persistence = []\n",
    "area = []\n",
    "\n",
    "for pi, (i, j) in enumerate(pairs):\n",
    "    \n",
    "    if pi % 10000 == 0:\n",
    "        print(pi, \"/\", len(pairs))\n",
    "    \n",
    "    if j is None:\n",
    "        persistence.append(np.inf)\n",
    "        area.append(data.shape[0]*data.shape[1])\n",
    "    else:\n",
    "        persistence.append(insert_order[j][0] - insert_order[i][0])\n",
    "        feature = homology.extract_persistence_feature(i, j, mcomp, comp, V, coV, insert_order)\n",
    "        pixels = homology.convert_to_pixels(feature, comp, insert_order, dual=dual)\n",
    "        area.append(len(pixels))\n",
    "\n",
    "print(\"Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# P = []\n",
    "# A = []\n",
    "\n",
    "# for pi, (i, j) in enumerate(pairs):\n",
    "    \n",
    "#     if j is not None and comp.dims[i] == 0 and persistence[pi] > 0:\n",
    "#         P.append(persistence[pi])\n",
    "#         A.append(area[pi])\n",
    "    \n",
    "\n",
    "# g = sns.JointGrid(np.log10(P), np.log10(A))\n",
    "# g.plot_joint(plt.scatter, marker='.', s=8, color='b', label=\"Valleys\")\n",
    "\n",
    "# g.plot_marginals(sns.distplot, kde=False)\n",
    "\n",
    "# ax = g.ax_joint\n",
    "# ax.set_xlabel(r\"$\\log_{10}$Persistence [height]\")\n",
    "# ax.set_ylabel(r'$\\log_{10}$Area [pixels$^2$]')\n",
    "# ax.legend(fontsize='large')\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# P = []\n",
    "# A = []\n",
    "\n",
    "# for pi, (i, j) in enumerate(pairs):\n",
    "    \n",
    "#     if j is not None and comp.dims[i] == 1 and persistence[pi] > 0:\n",
    "#         P.append(persistence[pi])\n",
    "#         A.append(area[pi])\n",
    "    \n",
    "\n",
    "# g = sns.JointGrid(np.log10(P), np.log10(A))\n",
    "# g.plot_joint(plt.scatter, marker='.', s=8, color='b', label=\"Mountains\")\n",
    "\n",
    "# g.plot_marginals(sns.distplot, kde=False)\n",
    "\n",
    "# ax = g.ax_joint\n",
    "# ax.set_xlabel(r\"$\\log_{10}$Persistence [height]\")\n",
    "# ax.set_ylabel(r'$\\log_{10}$Area [pixels$^2$]')\n",
    "# ax.legend(fontsize='large')\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "P = []\n",
    "A = []\n",
    "\n",
    "for pi, (i, j) in enumerate(pairs):\n",
    "    \n",
    "    if j is not None and persistence[pi] > 0:\n",
    "        P.append(persistence[pi])\n",
    "        A.append(area[pi])\n",
    "    \n",
    "\n",
    "g = sns.JointGrid(np.log10(P), np.log10(A))\n",
    "g.plot_joint(plt.scatter, marker='.', s=8, color='b', label=\"Mountains + Valleys\")\n",
    "\n",
    "g.plot_marginals(sns.distplot, kde=False)\n",
    "\n",
    "\n",
    "P = []\n",
    "A = []\n",
    "\n",
    "for pi, (i, j) in enumerate(pairs):\n",
    "    \n",
    "    if j is not None and persistence[pi] > 1e-2 and area[pi] > 8e2:\n",
    "        P.append(persistence[pi])\n",
    "        A.append(area[pi])\n",
    "    \n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(np.log10(P).reshape((len(P), 1)), np.log10(A).reshape((len(P), 1)))\n",
    "\n",
    "ax = g.ax_joint\n",
    "\n",
    "ax.scatter(np.log10(P), np.log10(A), marker='.', s=8, color='r')\n",
    "\n",
    "ax.plot(np.linspace(np.min(np.log10(P)), np.max(np.log10(P)), 100), \n",
    "    regr.predict(np.linspace(np.min(np.log10(P)), np.max(np.log10(P)), 100).reshape((100, 1))).reshape(100), \n",
    "    'k--', label=r'$A= {:.1f} P^{{{:.1f}}} $'.format(regr.intercept_[0], regr.coef_[0,0]))\n",
    "\n",
    "ax.set_xlabel(r\"$\\log_{10}$Persistence [height]\")\n",
    "ax.set_ylabel(r'$\\log_{10}$Area [pixels$^2$]')\n",
    "ax.legend(fontsize='large')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "def plot_features(N_features, sorted_pairs):\n",
    "    \n",
    "    palette = it.cycle(['Blues_r', 'Greens_r', 'Purples_r', 'RdPu_r'])\n",
    "\n",
    "    \n",
    "    ls = mcolors.LightSource()\n",
    "    shaded = ls.hillshade(data, vert_exag=100, dx=1, dy=1).flatten()\n",
    "    \n",
    "    norm = mpl.colors.Normalize(vmin=0, vmax=1)\n",
    "    smap = cm.ScalarMappable(norm=norm, cmap=plt.cm.Greys_r)\n",
    "\n",
    "    image = smap.to_rgba(shaded).reshape((data.shape[0]*data.shape[1], 4))\n",
    "\n",
    "    flat = shaded.flatten()\n",
    "\n",
    "\n",
    "    cycle_skeleton = set()\n",
    "    \n",
    "    last_feature = set()\n",
    "    last_cycle = set()\n",
    "        \n",
    "    n = 0\n",
    "    count = 0\n",
    "    while count < N_features:\n",
    "\n",
    "        (p, (i, j)) = sorted_pairs[n]\n",
    "        \n",
    "        n += 1\n",
    "        \n",
    "        feature = homology.extract_persistence_feature(i, j, mcomp, comp, V, coV, insert_order)\n",
    "        pixels = list(homology.convert_to_pixels(feature, comp, insert_order, dual=dual))\n",
    "        \n",
    "        last_feature = pixels\n",
    "        \n",
    "        if mcomp.get_dim(i) == 0:\n",
    "            \n",
    "            smap = cm.ScalarMappable(norm=norm, cmap=next(palette))\n",
    "            image[pixels] = smap.to_rgba(flat[pixels])\n",
    "            \n",
    "            last_basin = pixels\n",
    "            \n",
    "            pass\n",
    "            \n",
    "        elif mcomp.get_dim(i) == 1:\n",
    "            \n",
    "            bound = homology.get_boundary(feature, comp)\n",
    "            pixels = homology.convert_to_pixels(bound, comp, insert_order, dual=dual)\n",
    "            \n",
    "            cycle_skeleton.update(pixels)\n",
    "            \n",
    "            last_cycle = pixels\n",
    "\n",
    "            pass\n",
    "            \n",
    "        count += 1\n",
    "\n",
    "    print(sorted_pairs[N_features-1], mcomp.get_dim(sorted_pairs[N_features-1][1][0]))\n",
    "     \n",
    "    smap = cm.ScalarMappable(norm=norm, cmap='Oranges_r')\n",
    "    image[last_feature] = smap.to_rgba(flat[last_feature])\n",
    "    \n",
    "    image[list(cycle_skeleton)] = (0.0, 0.0, 0.0, 1.0)\n",
    "    \n",
    "        \n",
    "    if mcomp.get_dim(sorted_pairs[N_features-1][1][0]) == 1:\n",
    "        \n",
    "        h = \"e7298a\"\n",
    "        color = list(int(h[i:i+2], 16) / 256.0 for i in (0, 2 ,4))\n",
    "        color.append(1)\n",
    "        \n",
    "        image[list(last_cycle)] = color\n",
    "        \n",
    "        pass\n",
    "          \n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(16, 16))\n",
    "    \n",
    "    ax.imshow(image.reshape((data.shape[0], data.shape[1], 4)))\n",
    "\n",
    "\n",
    "    ax.axis('off')\n",
    "    plt.show()\n",
    "        \n",
    "persistence = []\n",
    "for (i, j) in pairs:\n",
    "    if j is not None:\n",
    "        persistence.append((insert_order[j][0] - insert_order[i][0], (i, j)))\n",
    "\n",
    "persistence = sorted(persistence, reverse=True)\n",
    "\n",
    "print(len(persistence))\n",
    "\n",
    "for n in range(len(persistence)):\n",
    "    \n",
    "    print(n)\n",
    "    \n",
    "    if n > 2:\n",
    "        break\n",
    "    \n",
    "    plot_features(n+1, persistence)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TIME = 0\n",
    "data = {}\n",
    "for (i, j) in pairs:\n",
    "    if j is not None:\n",
    "        data[(i, j)] = insert_order[j][TIME] - insert_order[i][TIME]\n",
    "    else:\n",
    "        data[(i, j)] = np.inf\n",
    "        \n",
    "pickle.dump(data, open(\"{}_X{}Y{}_persist.pkl\".format(label, X, Y), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "persist_data = {}\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "\n",
    "        persist_data[(i, j)] = pickle.load(open(\"{}_X{}Y{}_persist.pkl\".format(\"Z16\", i, j), 'rb'))\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8,8))\n",
    "\n",
    "for (i, j) in persist_data:\n",
    "    persist = []\n",
    "\n",
    "    for pair in persist_data[(i, j)]:\n",
    "        if persist_data[(i, j)][pair] != np.inf:\n",
    "            persist.append(persist_data[(i, j)][pair])\n",
    "\n",
    "\n",
    "\n",
    "    sns.distplot(np.log10(persist), ax=ax, kde=False, norm_hist=True, \n",
    "                 hist_kws={\"cumulative\": True, \"histtype\": \"step\", \"linewidth\": 1, \"alpha\":1.0, \"color\": 'b'})\n",
    "    \n",
    "    \n",
    "persist_data = {}\n",
    "\n",
    "for i in range(1):\n",
    "    for j in range(1):\n",
    "\n",
    "        persist_data[(i, j)] = pickle.load(open(\"{}_X{}Y{}_persist.pkl\".format(\"Z8\", i, j), 'rb'))\n",
    "\n",
    "\n",
    "for (i, j) in persist_data:\n",
    "    persist = []\n",
    "\n",
    "    for pair in persist_data[(i, j)]:\n",
    "        if persist_data[(i, j)][pair] != np.inf:\n",
    "            persist.append(persist_data[(i, j)][pair])\n",
    "\n",
    "\n",
    "\n",
    "    sns.distplot(np.log10(persist), ax=ax, kde=False, norm_hist=True, \n",
    "                 hist_kws={\"cumulative\": True, \"histtype\": \"step\", \"linewidth\": 1, \"alpha\":1.0, \"color\": 'r'})\n",
    "    \n",
    "persist_data = {}\n",
    "\n",
    "for i in range(1):\n",
    "    for j in range(1):\n",
    "\n",
    "        persist_data[(i, j)] = pickle.load(open(\"{}_X{}Y{}_persist.pkl\".format(\"Z4\", i, j), 'rb'))\n",
    "\n",
    "\n",
    "for (i, j) in persist_data:\n",
    "    persist = []\n",
    "\n",
    "    for pair in persist_data[(i, j)]:\n",
    "        if persist_data[(i, j)][pair] != np.inf and persist_data[(i, j)][pair] != 0:\n",
    "            persist.append(persist_data[(i, j)][pair])\n",
    "\n",
    "\n",
    "\n",
    "    sns.distplot(np.log10(persist), ax=ax, kde=False, norm_hist=True, \n",
    "                 hist_kws={\"cumulative\": True, \"histtype\": \"step\", \"linewidth\": 1, \"alpha\":1.0, \"color\": 'g'})\n",
    "\n",
    "    \n",
    "persist_data = {}\n",
    "\n",
    "for i in range(1):\n",
    "    for j in range(1):\n",
    "\n",
    "        persist_data[(i, j)] = pickle.load(open(\"{}_X{}Y{}_persist.pkl\".format(\"Z1\", i, j), 'rb'))\n",
    "\n",
    "for (i, j) in persist_data:\n",
    "    persist = []\n",
    "\n",
    "    for pair in persist_data[(i, j)]:\n",
    "        if persist_data[(i, j)][pair] != np.inf and persist_data[(i, j)][pair] != 0:\n",
    "            persist.append(persist_data[(i, j)][pair])\n",
    "\n",
    "\n",
    "\n",
    "    sns.distplot(np.log10(persist), ax=ax, kde=False, norm_hist=True, \n",
    "                 hist_kws={\"cumulative\": True, \"histtype\": \"step\", \"linewidth\": 2, \"alpha\":1.0, \"color\": 'm'})\n",
    "\n",
    "ax.set_xlabel(r\"$\\log_{10}$Persistence\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import mixture, cluster, manifold\n",
    "\n",
    "P = []\n",
    "A = []\n",
    "\n",
    "for pi, (i, j) in enumerate(pairs):\n",
    "    \n",
    "    if j is not None and persistence[pi] > 0:\n",
    "        P.append(persistence[pi])\n",
    "        A.append(area[pi])\n",
    "\n",
    "X = np.log10(np.vstack((P, A)).T)\n",
    "\n",
    "n_clusters = 2\n",
    "\n",
    "print(\"Gaussian Mixture Model\")\n",
    "\n",
    "model = mixture.GaussianMixture(n_components=n_clusters, covariance_type='full')\n",
    "\n",
    "model.fit(X)\n",
    "print(model.bic(X))\n",
    "      \n",
    "Y = model.predict(X)\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(6,6))\n",
    "\n",
    "palette = it.cycle(sns.color_palette(\"deep\"))\n",
    "\n",
    "for i ,(mean, cov) in enumerate(zip(model.means_, model.covariances_)):\n",
    "    \n",
    "    color = next(palette)\n",
    "    \n",
    "    ax.scatter(X[Y == i, 0], X[Y == i, 1], marker='.', s=8, color=color)\n",
    "\n",
    "\n",
    "#     v, w = la.eigh(cov)\n",
    "#     angle = np.arctan2(w[0][1], w[0][0])\n",
    "#     angle = 180. * angle / np.pi  # convert to degrees\n",
    "#     v = 2. * np.sqrt(2.) * np.sqrt(v)\n",
    "#     ell = mpl.patches.Ellipse(mean, v[0], v[1], 180. + angle, color='k')\n",
    "#     ell.set_clip_box(ax.bbox)\n",
    "#     ell.set_alpha(.5)\n",
    "#     ax.add_artist(ell)\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"K-Mean Clustering\")\n",
    "\n",
    "model = cluster.KMeans(n_clusters=n_clusters)\n",
    "\n",
    "model.fit(X)\n",
    "      \n",
    "Y = model.predict(X)\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(6,6))\n",
    "\n",
    "palette = it.cycle(sns.color_palette(\"deep\"))\n",
    "\n",
    "for i , center in enumerate(model.cluster_centers_):\n",
    "    \n",
    "    color = next(palette)\n",
    "    \n",
    "    ax.scatter(X[Y == i, 0], X[Y == i, 1], marker='.', s=8, color=color)\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# print(\"Mean-Shift\")\n",
    "\n",
    "\n",
    "\n",
    "# model = cluster.MeanShift()\n",
    "\n",
    "# model.fit(X)\n",
    "      \n",
    "# Y = model.predict(X)\n",
    "\n",
    "# fig, ax = plt.subplots(1,1, figsize=(6,6))\n",
    "\n",
    "# palette = it.cycle(sns.color_palette(\"deep\"))\n",
    "\n",
    "# for i , center in enumerate(model.cluster_centers_):\n",
    "    \n",
    "#     color = next(palette)\n",
    "    \n",
    "#     ax.scatter(X[Y == i, 0], X[Y == i, 1], marker='.', s=8, color=color)\n",
    "\n",
    "\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "import sys, os\n",
    "sys.path.insert(0, '../')\n",
    "sys.path.insert(0, '../python_src/')\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import numpy.ma as ma\n",
    "import scipy as sp\n",
    "import scipy.io as spio\n",
    "\n",
    "import matplotlib.pyplot as plt; plt.rcdefaults()\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib import collections as mc\n",
    "\n",
    "import itertools as it\n",
    "import collections as co\n",
    "import queue\n",
    "import networkx as nx\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "from skimage import filters as skifilters\n",
    "from skimage import color as skicolor\n",
    "\n",
    "from sklearn import linear_model\n",
    "\n",
    "import homology\n",
    "import persist\n",
    "\n",
    "mpl.rcParams['mathtext.fontset'] = 'cm'\n",
    "sns.set_context('poster', font_scale=1.25)\n",
    "sns.set(color_codes=True, palette='deep')\n",
    "sns.set_style('ticks', {'xtick.direction': 'in','ytick.direction': 'in', 'axes.linewidth': 2.0})\n",
    "\n",
    "\n",
    "\n",
    "def total_size(o, handlers={}, verbose=False):\n",
    "    \"\"\" Returns the approximate memory footprint an object and all of its contents.\n",
    "\n",
    "    Automatically finds the contents of the following builtin containers and\n",
    "    their subclasses:  tuple, list, deque, dict, set and frozenset.\n",
    "    To search other containers, add handlers to iterate over their contents:\n",
    "\n",
    "        handlers = {SomeContainerClass: iter,\n",
    "                    OtherContainerClass: OtherContainerClass.get_elements}\n",
    "\n",
    "    \"\"\"\n",
    "    dict_handler = lambda d: it.chain.from_iterable(d.items())\n",
    "    all_handlers = {tuple: iter,\n",
    "                    list: iter,\n",
    "                    co.deque: iter,\n",
    "                    dict: dict_handler,\n",
    "                    set: iter,\n",
    "                    frozenset: iter,\n",
    "                   }\n",
    "    all_handlers.update(handlers)     # user handlers take precedence\n",
    "    seen = set()                      # track which object id's have already been seen\n",
    "    default_size = sys.getsizeof(0)       # estimate sizeof object without __sizeof__\n",
    "\n",
    "    def sizeof(o):\n",
    "        if id(o) in seen:       # do not double count the same object\n",
    "            return 0\n",
    "        seen.add(id(o))\n",
    "        s = sys.getsizeof(o, default_size)\n",
    "\n",
    "        if verbose:\n",
    "            print(s, type(o), repr(o), file=sys.stderr)\n",
    "\n",
    "        for typ, handler in all_handlers.items():\n",
    "            if isinstance(o, typ):\n",
    "                s += sum(map(sizeof, handler(o)))\n",
    "                break\n",
    "                \n",
    "                \n",
    "        if not hasattr(o.__class__, '__slots__'):\n",
    "            if hasattr(o, '__dict__'):\n",
    "                s+=sizeof(o.__dict__) # no __slots__ *usually* means a __dict__, but some special builtin classes (such as `type(None)`) have neither\n",
    "            # else, `o` has no attributes at all, so sys.getsizeof() actually returned the correct value\n",
    "        else:\n",
    "            s+=sum(sizeof(getattr(o, x)) for x in o.__class__.__slots__ if hasattr(o, x))\n",
    "                   \n",
    "        \n",
    "        return s\n",
    "    \n",
    "    return sizeof(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "label = 'Z16'\n",
    "\n",
    "mat = spio.loadmat(\"../sample_data/{}.mat\".format(label))\n",
    "# data = np.nan_to_num(mat[label][1450:1500, 1450:1500])\n",
    "data = mat[label]\n",
    "\n",
    "# mat = spio.loadmat(\"Everest.mat\")\n",
    "# data = mat['Expression1']\n",
    "\n",
    "print(total_size(mat))\n",
    "\n",
    "# dx = 5280 * data.shape[0] / 20\n",
    "# dy = 5280 * data.shape[1] / 20\n",
    "\n",
    "# data = mpimg.imread('2D6185C9-1DD8-B71C-076FF6978423E103-large.jpg')[:,:,:3]\n",
    "# data = mpimg.imread('20170105_100151.jpg')[:,:,:3]\n",
    "# # data = mpimg.imread('2018-01-12.png')[:,:,:3]\n",
    "\n",
    "# data = skicolor.rgb2gray(data)\n",
    "# data = skifilters.laplace(data)\n",
    "\n",
    "# data = np.zeros([100, 100], float)\n",
    "# data[50, 50] = -1\n",
    "\n",
    "# print(np.min(data), np.max(data))\n",
    "\n",
    "\n",
    "# data = np.array([[10, 0, 10],\n",
    "#                 [2, 1, 2],                        \n",
    "#                 [3, 6, 3],\n",
    "#                 [4, 5, 4]])\n",
    "\n",
    "# data = np.array([[3,2,2],\n",
    "#                 [3,1,1],\n",
    "#                 [0,1,0]])\n",
    "\n",
    "# data = np.array([[8, 3, 2],\n",
    "#                 [7, np.nan, 1],\n",
    "#                 [6, 9, 1],\n",
    "#                 [5, 10, 0]])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data = ma.masked_invalid(data)\n",
    "\n",
    "print(data.shape)\n",
    "\n",
    "ls = mcolors.LightSource()\n",
    "\n",
    "# norm = mpl.colors.Normalize(vmin=np.min(data),vmax=np.max(data))\n",
    "norm = mpl.colors.Normalize(vmin=0,vmax=1)\n",
    "cmap = plt.cm.Blues_r\n",
    "smap = cm.ScalarMappable(norm=norm, cmap=cmap)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "# im = ax.imshow(smap.to_rgba(data))\n",
    "\n",
    "image = smap.to_rgba(ls.hillshade(data, vert_exag=100, dx=1, dy=1)).reshape([data.shape[0]*data.shape[1], 4])\n",
    "\n",
    "h = \"ff7f00\"\n",
    "color = list(int(h[i:i+2], 16) / 256.0 for i in (0, 2 ,4))\n",
    "color.append(1)\n",
    "image[data.mask.flatten()] = color\n",
    "im = ax.imshow(image.reshape([data.shape[0], data.shape[1], 4]))\n",
    "\n",
    "\n",
    "\n",
    "# ax.hlines(np.linspace(int(data.shape[0]/3), 2*int(data.shape[0]/3), 2), 0, data.shape[1])\n",
    "# ax.vlines(np.linspace(int(data.shape[1]/3), 2*int(data.shape[1]/3), 2), 0, data.shape[0])\n",
    "\n",
    "# sns.set_style('ticks', {'xtick.direction': 'out', 'xtick.major.size': 3.0,\n",
    "#                         'ytick.direction': 'out', 'ytick.major.size': 2.0, 'axes.linewidth': 1.0})\n",
    "\n",
    "# cax = fig.add_axes([0.92, 0.10, 0.03, 0.80])\n",
    "# cbar = mpl.colorbar.ColorbarBase(cax, cmap=cmap,\n",
    "#                                 norm=norm,\n",
    "#                                 orientation='vertical')\n",
    "\n",
    "\n",
    "# ax.vlines([-0.5 + j for j in np.arange(data.shape[0])], -0.5, data.shape[1]-0.5, \n",
    "#           lw=2.0, alpha=0.75, color=\"#969696\")\n",
    "# ax.hlines([-0.5 + i for i in np.arange(data.shape[1])], -0.5, data.shape[0]-0.5, \n",
    "#           lw=2.0, alpha=0.75, color=\"#969696\")\n",
    "\n",
    "# ax.vlines([-0.5+1492-1000, -0.5+1508-1000], -0.5+1492-1000, -0.5+1508-1000, \n",
    "#           lw=2.0)\n",
    "# ax.hlines([-0.5+1492-1000, -0.5+1508-1000], -0.5+1492-1000, -0.5+1508-1000, \n",
    "#           lw=2.0)\n",
    "\n",
    "# cbar.set_label(r\"Height\")\n",
    "\n",
    "ax.axis('off')\n",
    "\n",
    "# plt.savefig(\"crumple_16x_network.png\", bbox_inches='tight')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# X = 1\n",
    "# Y = 1\n",
    "\n",
    "# data = data[Y*int(data.shape[0]/2):(Y+1)*int(data.shape[0]/2), \n",
    "#             X*int(data.shape[1]/2):(X+1)*int(data.shape[1]/2)]\n",
    "\n",
    "# print(data.shape)\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(16,16))\n",
    "# im = ax.imshow(smap.to_rgba(ls.hillshade(data, vert_exag=100, dx=1, dy=1)))\n",
    "\n",
    "# ax.axis('off')\n",
    "# plt.show()\n",
    "# print(total_size(data))\n",
    "\n",
    "print(len(np.unique(data)), data.size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "dual = True\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "print(\"Constructing complex\", flush=True)\n",
    "\n",
    "comp = persist.construct_masked_cubical_complex(data.mask.flatten(), data.shape, False, dual)\n",
    "\n",
    "# comp = persist.construct_cubical_complex(data.shape, False, dual)\n",
    "\n",
    "# for c in range(comp.ncells):\n",
    "#     print(c, comp.get_label(c), comp.get_dim(c), comp.get_facets(c), comp.get_coeffs(c))\n",
    "\n",
    "print(\"Checking boundary operator\", flush=True)\n",
    "print(persist.check_boundary_op(comp))\n",
    "\n",
    "print(total_size(comp))\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Elapsed Time:\", end - start)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "print(\"Finding pixel order\", flush=True)\n",
    "\n",
    "filtration = persist.Filtration(comp.ncells, data[~data.mask].flatten())\n",
    "persist.perform_watershed_transform(filtration, comp, dual)\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Elapsed Time:\", end - start)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "print(\"Finding Filtration Order\", flush=True)\n",
    "\n",
    "persist.construct_filtration(filtration, comp, dual)\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Elapsed Time:\", end - start)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "print(\"Constructing discrete gradient\", flush=True)\n",
    "\n",
    "V, coV = persist.construct_discrete_gradient(filtration, comp, dual)\n",
    "\n",
    "\n",
    "print(total_size(V), total_size(coV))\n",
    "\n",
    "# print(V)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Elapsed Time:\", end - start)\n",
    "\n",
    "n = 0\n",
    "for v in range(len(V)):\n",
    "    \n",
    "    if V[v] == v:\n",
    "#         print(v, V[v], comp.get_label(c))\n",
    "        n += 1\n",
    "        \n",
    "\n",
    "print(\"Number Critical Cells:\", n)\n",
    "\n",
    "\n",
    "# # print(V)\n",
    "# # print(coV)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "print(\"Calculating Morse complex\", flush=True)\n",
    "mcomp = persist.construct_morse_complex(V, comp, False)\n",
    "\n",
    "print(\"Checking boundary operator\", flush=True)\n",
    "print(homology.check_boundary_op(mcomp))\n",
    "\n",
    "\n",
    "# for c in range(mcomp.ncells):\n",
    "#     print(c, mcomp.get_label(c), mcomp.get_dim(c), mcomp.get_facets(c), mcomp.get_coeffs(c))\n",
    "# for c in range(mcomp.ncells):\n",
    "#     print(c, mcomp.get_label(c), mcomp.get_dim(c), mcomp.get_cofacets(c))\n",
    "\n",
    "print(total_size(mcomp))\n",
    "\n",
    "end = time.time()\n",
    "print(\"Elapsed Time:\", end - start)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "print(\"Finding basins\", flush=True)\n",
    "basins = persist.find_basins(mcomp, coV, filtration, comp, dual)\n",
    "print(\"Basins:\", len(basins))\n",
    "\n",
    "print(total_size(basins))\n",
    "\n",
    "print(\"Calculating Morse skeleton\", flush=True)\n",
    "skeleton = persist.find_morse_skeleton(mcomp, 1, V, filtration, comp, dual)\n",
    "\n",
    "print(total_size(skeleton))\n",
    "\n",
    "end = time.time()\n",
    "print(\"Elapsed Time:\", end - start)\n",
    "\n",
    "palette1 = it.cycle(sns.color_palette(\"deep\"))\n",
    "palette2 = it.cycle(['Blues_r', 'Greens_r', 'Purples_r', 'Oranges_r', 'RdPu_r'])\n",
    "\n",
    "basin_color_map1 = {}\n",
    "basin_color_map2 = {}\n",
    "for v in sorted(basins):\n",
    "# for v in mcomp.get_cells():\n",
    "#     if mcomp.dims[v]== 0:\n",
    "    basin_color_map1[v] = next(palette1)\n",
    "    basin_color_map2[v] = next(palette2)\n",
    "\n",
    "print(\"Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "\n",
    "# image = np.ones([data.shape[0]*data.shape[1], 3])\n",
    "\n",
    "# for i in basins:\n",
    "#     image[list(basins[i])] = basin_color_map1[i]\n",
    "    \n",
    "# image[list(skeleton)] = (0.0, 0.0, 0.0)\n",
    "\n",
    "# # for i in basins:\n",
    "# #     image[i] = (1.0, 1.0, 1.0)\n",
    "        \n",
    "# print(np.min(data), np.max(data))\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(16, 16))\n",
    "# ax.imshow(image.reshape((data.shape[0], data.shape[1], 3)))\n",
    "# ax.axis('off')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "\n",
    "image = np.zeros([data.shape[0]*data.shape[1], 4])   \n",
    "\n",
    "ls = mcolors.LightSource()\n",
    "shaded = ls.hillshade(data, vert_exag=100, dx=1, dy=1).flatten()\n",
    "\n",
    "for i in basins:\n",
    "    \n",
    "#     norm = mpl.colors.Normalize(vmin=np.min(data), vmax=np.max(data))\n",
    "#     smap = cm.ScalarMappable(norm=norm, cmap=basin_color_map2[i])\n",
    "#     image[list(basins[i])] = smap.to_rgba(vertex_time[list(basins[i])])\n",
    "    \n",
    "    norm = mpl.colors.Normalize(vmin=0, vmax=1)\n",
    "    smap = cm.ScalarMappable(norm=norm, cmap=basin_color_map2[i])\n",
    "    image[list(basins[i])] = smap.to_rgba(shaded[list(basins[i])])\n",
    "    \n",
    "\n",
    "image[list(skeleton)] = (0.0, 0.0, 0.0, 1.0)\n",
    "\n",
    "for i in basins:\n",
    "    image[i] = (1.0, 1.0, 1.0, 1.0)\n",
    "\n",
    "h = \"ff7f00\"\n",
    "color = list(int(h[i:i+2], 16) / 256.0 for i in (0, 2 ,4))\n",
    "color.append(1)\n",
    "image[data.mask.flatten()] = color\n",
    "\n",
    "print(np.min(data), np.max(data))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.imshow(image.reshape((data.shape[0], data.shape[1], 4)))\n",
    "ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "print(\"Simplifying Morse Complex\")\n",
    "\n",
    "# V, coV = homology.simplify_morse_complex(1e1, V, coV, comp, insert_order)\n",
    "\n",
    "persist.simplify_morse_complex(1e1, V, coV, filtration, comp, verbose=True)\n",
    "\n",
    "\n",
    "n = 0\n",
    "for v in V:\n",
    "    if v == V[v]:\n",
    "#         print(v, comp.dims[v])\n",
    "        n += 1\n",
    "\n",
    "end = time.time()\n",
    "print(\"Elapsed Time:\", end-start)\n",
    "    \n",
    "print(\"Calculating Morse complex\")\n",
    "mcomp = persist.construct_morse_complex(V, comp, False)\n",
    "\n",
    "print(\"Checking boundary operator\")\n",
    "print(persist.check_boundary_op(mcomp))\n",
    "\n",
    "print(\"Finding basins\")\n",
    "basins = persist.find_basins(mcomp, coV, filtration, comp, dual)\n",
    "\n",
    "print(\"Calculating Morse skeleton\")\n",
    "skeleton = persist.find_morse_skeleton(mcomp, 1, V, filtration, comp, dual)\n",
    "\n",
    "    \n",
    "print(\"Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "print(\"Calculating persistence pairs...\")\n",
    "\n",
    "mfiltration = homology.construct_filtration(mcomp, filtration)\n",
    "\n",
    "# weights = homology.get_morse_weights(mcomp, V, coV, comp.facets, comp.cofacets)\n",
    "   \n",
    "# print(\"Weights:\", weights)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "mpairs = homology.compute_persistence(mcomp, mfiltration)\n",
    "# (pairs, bcycles) = homology.compute_persistence(mcomp, filtration, \n",
    "#                                                             birth_cycles=True, optimal_cycles=False)\n",
    "# (pairs, bcycles, ocycles) = homology.compute_persistence(mcomp, filtration, \n",
    "#                                                             birth_cycles=True, optimal_cycles=True,\n",
    "#                                                                     weights=weights, relative_cycles=True)\n",
    "\n",
    "print(\"Number Pairs:\", len(mpairs))\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Elapsed Time:\", end - start)\n",
    "\n",
    "# print(\"Pairs:\", pairs)\n",
    "# print(\"Birth Cycles:\", bcycles)\n",
    "# print(\"Death Cycles:\", ocycles)\n",
    "\n",
    "pairs = []\n",
    "for (i, j) in mpairs:\n",
    "    if j is not None:\n",
    "        pairs.append((mcomp.get_label(i), mcomp.get_label(j)))\n",
    "    else:\n",
    "        pairs.append((mcomp.get_label(i), None))\n",
    "        print(\"Infinite Persistence:\", mcomp.get_label(i), \"Dim\", mcomp.get_dim(i))\n",
    "\n",
    "    \n",
    "print(\"Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.set_context(\"talk\", font_scale=1.5)\n",
    "\n",
    "TIME = 0\n",
    "\n",
    "birth = [[] for i in range(comp.dim+1)]\n",
    "death = [[] for i in range(comp.dim+1)]\n",
    "\n",
    "for (i, j) in pairs:\n",
    "    \n",
    "    d = comp.get_dim(i)\n",
    "    birth[d].append(filtration.get_time(i))\n",
    "    if j is not None:\n",
    "        death[d].append(filtration.get_time(j))\n",
    "    else:\n",
    "        death[d].append(filtration.get_time(i))\n",
    "    \n",
    "fig = plt.figure(figsize=(8,8))\n",
    "    \n",
    "ax1 = fig.add_subplot(1,1,1)\n",
    "\n",
    "ax1.scatter(birth[0], death[0], marker='.', color='b', label=\"$0$-cycles\")\n",
    "ax1.scatter(death[1], birth[1], marker='.', color='r', label=\"$1$-cycles\")\n",
    "# ax1.scatter(birth[1], death[1], marker='.', color='b', label=\"$0$-cycles\")\n",
    "\n",
    "ax1.plot(np.linspace(np.min(data), np.max(data), 100), np.linspace(np.min(data), np.max(data), 100), 'k--')\n",
    "\n",
    "# ax1.set_title(r\"$d={}$\".format(0))\n",
    "\n",
    "ax1.set_xlabel(r\"Birth [height]\")\n",
    "ax1.set_ylabel(r\"Death [height]\")\n",
    "\n",
    "# ax1.legend(fontsize='large')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig(\"basin_persistence.png\", bbox_inches='tight', dpi=200)\n",
    "# plt.savefig(\"peak_persistence.png\", bbox_inches='tight', dpi=200)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "TIME = 0\n",
    "\n",
    "birth = [[] for i in range(mcomp.dim+1)]\n",
    "persistence = [[] for i in range(mcomp.dim+1)]\n",
    "\n",
    "for (i, j) in pairs:\n",
    "    \n",
    "    if j is None or filtration.get_time(i) == filtration.get_time(j):\n",
    "        continue\n",
    "        \n",
    "    \n",
    "    \n",
    "    d = comp.get_dim(i)\n",
    "    birth[d].append(filtration.get_time(i))\n",
    "    persistence[d].append(filtration.get_time(j)-filtration.get_time(i))\n",
    "\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "        \n",
    "ax1 = fig.add_subplot(1,1,1)\n",
    "\n",
    "ax1.set_yscale('log')\n",
    "\n",
    "ax1.scatter(birth[0], persistence[0], marker='.', color='b', label=\"$0$-cycles\")\n",
    "ax1.scatter(birth[1], persistence[1], marker='.', color='r', label=\"$1$-cycles\")\n",
    "\n",
    "ax1.set_xlabel(r\"Birth [height]\")\n",
    "ax1.set_ylabel(r\"Persistence [height]\")\n",
    "# ax1.set_ylim(1e-8, 1e0)\n",
    "\n",
    "# ax1.hlines(10**(-1.9), -0.4, 1.0)\n",
    "\n",
    "# ax1.legend(fontsize='large')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "persistence = []\n",
    "area = []\n",
    "\n",
    "for pi, (mi, mj) in enumerate(mpairs):\n",
    "    \n",
    "    (i, j) = pairs[pi]\n",
    "    \n",
    "    if pi % 10000 == 0:\n",
    "        print(pi, \"/\", len(pairs), flush=True)\n",
    "    \n",
    "    if j is None:\n",
    "        persistence.append(np.inf)\n",
    "        area.append(data.shape[0]*data.shape[1])\n",
    "    else:\n",
    "        persistence.append(filtration.get_time(j) - filtration.get_time(i))\n",
    "        feature = persist.extract_persistence_feature(mi, mj, mcomp, V, coV, filtration, comp)\n",
    "        pixels = persist.convert_to_pixels(feature, filtration, comp, dual)\n",
    "        area.append(len(pixels))\n",
    "\n",
    "print(\"Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.set_context(\"talk\", font_scale=1.5)\n",
    "\n",
    "\n",
    "P = []\n",
    "A = []\n",
    "\n",
    "max_H = np.max(data) - np.min(data)\n",
    "max_A = ma.count(data)\n",
    "\n",
    "for pi, (i, j) in enumerate(pairs):\n",
    "    \n",
    "    if j is not None and persistence[pi] > 0:\n",
    "        P.append(persistence[pi] / max_H)\n",
    "        A.append(area[pi] / max_A)\n",
    "    \n",
    "\n",
    "g = sns.JointGrid(np.log10(P), np.log10(A), size=8)\n",
    "g.plot_joint(plt.scatter, marker='.', color='b', label=\"Peaks + Basins\")\n",
    "\n",
    "g.plot_marginals(sns.distplot, kde=False)\n",
    "\n",
    "\n",
    "P = []\n",
    "A = []\n",
    "sigma = []\n",
    "\n",
    "for pi, (i, j) in enumerate(pairs):\n",
    "    \n",
    "    if j is not None and persistence[pi] / max_H > 2e-3 and area[pi]/ max_A > 3e-4:\n",
    "        P.append(persistence[pi] / max_H)\n",
    "        A.append(area[pi] / max_A)\n",
    "        sigma.append(0.5*np.log10((area[pi]+np.sqrt(area[pi]))/max_A)\n",
    "                          -0.5*np.log10((area[pi]-np.sqrt(area[pi])) / max_A))\n",
    "    \n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(np.log10(P).reshape((len(P), 1)), np.log10(A).reshape((len(P), 1)), sample_weight=1.0/np.array(sigma)**2)\n",
    "\n",
    "ax = g.ax_joint\n",
    "\n",
    "ax.scatter(np.log10(P), np.log10(A), marker='.', color='r')\n",
    "\n",
    "ax.plot(np.linspace(np.min(np.log10(P)), np.max(np.log10(P)), 100), \n",
    "    regr.predict(np.linspace(np.min(np.log10(P)), np.max(np.log10(P)), 100).reshape((100, 1))).reshape(100), \n",
    "    'k--', label=r'$A= {:.1f} P^{{{:.1f}}} $'.format(regr.intercept_[0], regr.coef_[0,0]))\n",
    "\n",
    "ax.set_xlabel(r\"$\\log_{10}($Persistence / Max Height$)$\")\n",
    "ax.set_ylabel(r\"$\\log_{10}($Area / Total Area$)$\")\n",
    "ax.legend(fontsize='small')\n",
    "\n",
    "ax.set_xlim(-10, 0)\n",
    "ax.set_ylim(-7, 0)\n",
    "\n",
    "# plt.savefig(\"area_dist.png\", bbox_inches='tight', dpi=200)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_H = np.max(data) - np.min(data)\n",
    "max_A = ma.count(data)\n",
    "P = []\n",
    "A = []\n",
    "sigma = []\n",
    "\n",
    "for pi, (i, j) in enumerate(pairs):\n",
    "    \n",
    "    if j is not None and persistence[pi] / max_H > 2e-3 and area[pi]/ max_A > 3e-4:\n",
    "        P.append(persistence[pi] / max_H)\n",
    "        A.append(area[pi] / max_A)\n",
    "        sigma.append(0.5*np.log10((area[pi]+np.sqrt(area[pi]))/max_A)\n",
    "                          -0.5*np.log10((area[pi]-np.sqrt(area[pi])) / max_A))\n",
    "        \n",
    "        \n",
    "ax = sns.distplot(np.log10(A), kde=False)\n",
    "\n",
    "ax.set_ylim(1e-1, 1e2)\n",
    "\n",
    "ax.set_yscale('log')\n",
    "\n",
    "\n",
    "\n",
    "ax.set_xlabel(r\"$\\log_{10}($Area / Total Area$)$\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "def plot_features(N_features, sorted_pairs):\n",
    "    \n",
    "    palette = it.cycle(['Blues_r', 'Greens_r', 'Purples_r', 'RdPu_r'])\n",
    "\n",
    "    \n",
    "    ls = mcolors.LightSource()\n",
    "    shaded = ls.hillshade(data, vert_exag=100, dx=1, dy=1).flatten()\n",
    "    \n",
    "    norm = mpl.colors.Normalize(vmin=0, vmax=1)\n",
    "    smap = cm.ScalarMappable(norm=norm, cmap=plt.cm.Greys_r)\n",
    "\n",
    "    image = smap.to_rgba(shaded).reshape((data.shape[0]*data.shape[1], 4))\n",
    "\n",
    "    flat = shaded.flatten()\n",
    "\n",
    "\n",
    "    cycle_skeleton = set()\n",
    "    \n",
    "    last_feature = set()\n",
    "    last_cycle = set()\n",
    "        \n",
    "    n = 0\n",
    "    count = 0\n",
    "    while count < N_features:\n",
    "\n",
    "        (p, (i, j), (mi, mj)) = sorted_pairs[n]\n",
    "        \n",
    "        print(i, j, filtration.get_time(i), filtration.get_time(j))\n",
    "        \n",
    "        n += 1\n",
    "        \n",
    "        feature = persist.extract_persistence_feature(mi, mj, mcomp, V, coV, filtration, comp)\n",
    "                \n",
    "        pixels = list(persist.convert_to_pixels(feature, filtration, comp, dual))\n",
    "        \n",
    "        last_feature = pixels\n",
    "        \n",
    "        if mcomp.get_dim(mi) == 0:\n",
    "            \n",
    "            smap = cm.ScalarMappable(norm=norm, cmap=next(palette))\n",
    "            image[pixels] = smap.to_rgba(flat[pixels])\n",
    "            \n",
    "            last_basin = pixels\n",
    "            \n",
    "            pass\n",
    "            \n",
    "        elif mcomp.get_dim(mi) == 1:\n",
    "            \n",
    "            bound = homology.get_boundary(feature, comp)\n",
    "            pixels = persist.convert_to_pixels(bound, filtration, comp, dual)\n",
    "            \n",
    "            cycle_skeleton.update(pixels)\n",
    "            \n",
    "            last_cycle = pixels\n",
    "\n",
    "            pass\n",
    "            \n",
    "        count += 1\n",
    "\n",
    "    print(sorted_pairs[N_features-1], mcomp.get_dim(sorted_pairs[N_features-1][1][0]))\n",
    "     \n",
    "    smap = cm.ScalarMappable(norm=norm, cmap='Oranges_r')\n",
    "    image[last_feature] = smap.to_rgba(flat[last_feature])\n",
    "    \n",
    "    image[list(cycle_skeleton)] = (0.0, 0.0, 0.0, 1.0)\n",
    "    \n",
    "        \n",
    "    if mcomp.get_dim(sorted_pairs[N_features-1][2][0]) == 1:\n",
    "        \n",
    "        h = \"e7298a\"\n",
    "        color = list(int(h[i:i+2], 16) / 256.0 for i in (0, 2 ,4))\n",
    "        color.append(1)\n",
    "        \n",
    "        image[list(last_cycle)] = color\n",
    "                  \n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(16, 16))\n",
    "    \n",
    "    ax.imshow(image.reshape((data.shape[0], data.shape[1], 4)))\n",
    "\n",
    "\n",
    "    ax.axis('off')\n",
    "    plt.show()\n",
    "        \n",
    "persistence = []\n",
    "for (i, j), (mi, mj) in zip(pairs, mpairs):\n",
    "    if j is not None:\n",
    "        persistence.append((filtration.get_time(j) - filtration.get_time(i), (i, j), (mi, mj)))\n",
    "\n",
    "persistence = sorted(persistence, reverse=True)\n",
    "\n",
    "print(len(persistence))\n",
    "\n",
    "for n in range(len(persistence)):\n",
    "    \n",
    "    print(n)\n",
    "    \n",
    "    if n > 10:\n",
    "        break\n",
    "    \n",
    "    plot_features(n+1, persistence)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def show_topo_map(elevation, n=0):\n",
    "\n",
    "    print(n, elevation)\n",
    "    \n",
    "    ls = mcolors.LightSource()\n",
    "    shaded = ls.hillshade(data, vert_exag=100, dx=1, dy=1).flatten()\n",
    "\n",
    "    norm = mpl.colors.Normalize(vmin=0, vmax=1)\n",
    "    smap = cm.ScalarMappable(norm=norm, cmap=plt.cm.Greys_r)\n",
    "    image = smap.to_rgba(shaded).reshape((data.shape[0]*data.shape[1], 4))\n",
    "\n",
    "#     feature = np.where(data.flatten() <= elevation)[0]\n",
    "#     bounds = homology.convert_to_pixels(homology.get_boundary(set(feature), comp), comp, insert_order, dual=dual)\n",
    "\n",
    "#     smap = cm.ScalarMappable(norm=norm, cmap=plt.cm.Blues_r)\n",
    "#     image[feature] = smap.to_rgba(shaded.flatten()[feature])\n",
    "    \n",
    "    \n",
    "#     i = 3568334\n",
    "#     j = 1421863\n",
    "    \n",
    "#     feature = homology.extract_persistence_feature(i, j, mcomp, comp, V, coV, insert_order)\n",
    "#     pixels = np.array(list(homology.convert_to_pixels(feature, comp, insert_order, dual=dual)))\n",
    "    \n",
    "# #     basin = pixels[np.where(data.flatten()[pixels] <= elevation)[0]]\n",
    "#     smap = cm.ScalarMappable(norm=norm, cmap=plt.cm.Greens_r)\n",
    "# #     image[basin] = smap.to_rgba(shaded.flatten()[basin])\n",
    "    \n",
    "        \n",
    "#     basin_bounds = homology.convert_to_pixels(\n",
    "#     homology.get_boundary(set(pixels), comp), comp, insert_order, dual=dual)\n",
    "#     image[pixels] = smap.to_rgba(shaded.flatten()[pixels])\n",
    "    \n",
    "#     image[list(basin_bounds)] = (0.0, 0.0, 0.0, 1.0)\n",
    "    \n",
    "\n",
    "    i = 2182385\n",
    "    j = 384552\n",
    "    \n",
    "    feature = homology.extract_persistence_feature(i, j, mcomp, comp, V, coV, insert_order)\n",
    "    pixels = np.array(list(homology.convert_to_pixels(feature, comp, insert_order, dual=dual)))\n",
    "#     peak = pixels[np.where((data.flatten()[pixels] <= elevation) & (data.flatten()[pixels] > insert_order[i, 0]))[0]]\n",
    "    \n",
    "    smap = cm.ScalarMappable(norm=norm, cmap=plt.cm.Greens_r)\n",
    "#     image[peak] = smap.to_rgba(shaded.flatten()[peak])\n",
    "    \n",
    "#     peak_bounds = homology.convert_to_pixels(\n",
    "#         homology.get_boundary(set(peak), comp), comp, insert_order, dual=dual)\n",
    "    \n",
    "    \n",
    "    peak_bounds = homology.convert_to_pixels(\n",
    "        homology.get_boundary(set(pixels), comp), comp, insert_order, dual=dual)\n",
    "    image[pixels] = smap.to_rgba(shaded.flatten()[pixels])\n",
    "    \n",
    "    image[list(peak_bounds)] = (0.0, 0.0, 0.0, 1.0)\n",
    "    \n",
    "#     image[list(bounds)] = (0.0, 0.0, 0.0, 1.0)\n",
    "    \n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "    ax.imshow(image.reshape((data.shape[0], data.shape[1], 4)))\n",
    "    ax.axis('off')\n",
    "\n",
    "#     plt.savefig(\"figs/topo{:04d}.png\".format(n), bbox_inches='tight')\n",
    "\n",
    "\n",
    "#     plt.savefig(\"topo_basin_birth.png\", bbox_inches='tight')\n",
    "#     plt.savefig(\"topo_basin_during1.png\", bbox_inches='tight')\n",
    "#     plt.savefig(\"topo_basin_death.png\", bbox_inches='tight')\n",
    "#     plt.savefig(\"topo_basin_feature.png\", bbox_inches='tight')\n",
    "\n",
    "\n",
    "#     plt.savefig(\"topo_peak_before.png\", bbox_inches='tight')\n",
    "#     plt.savefig(\"topo_peak_birth.png\", bbox_inches='tight')\n",
    "#     plt.savefig(\"topo_peak_during1.png\", bbox_inches='tight')\n",
    "#     plt.savefig(\"topo_peak_death.png\", bbox_inches='tight')\n",
    "#     plt.savefig(\"topo_peak_feature.png\", bbox_inches='tight')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# for n, h in enumerate(np.linspace(np.min(data), np.max(data), 40)):\n",
    "#     show_topo_map(h, n)\n",
    "\n",
    "ti = insert_order[3568334, 0]\n",
    "tj = insert_order[1421863, 0]\n",
    "\n",
    "# ti = insert_order[2182385, 0]\n",
    "# tj = insert_order[384552, 0]\n",
    "\n",
    "print(ti, tj)\n",
    "# # show_topo_map(ti)\n",
    "# show_topo_map(ti+0.05)\n",
    "# # show_topo_map(ti+(tj-ti)/2)\n",
    "# # show_topo_map(tj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "def createGIF(iname, oname, show=True, delay=10):\n",
    "        \n",
    "    os.system(\"convert -delay {0} -loop 0 {1} {2}\".format(delay, iname, oname))\n",
    "\n",
    "    if show:\n",
    "        \n",
    "        IMG_TAG = \"\"\"<img src=\"{0}\" alt=\"some_text\">\"\"\".format(oname)\n",
    "\n",
    "        display(HTML(IMG_TAG))\n",
    "        \n",
    "createGIF(\"figs/topo*.png\", \"topo.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TIME = 0\n",
    "data = {}\n",
    "for (i, j) in pairs:\n",
    "    if j is not None:\n",
    "        data[(i, j)] = insert_order[j][TIME] - insert_order[i][TIME]\n",
    "    else:\n",
    "        data[(i, j)] = np.inf\n",
    "        \n",
    "pickle.dump(data, open(\"{}_X{}Y{}_persist.pkl\".format(label, X, Y), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "persist_data = {}\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "\n",
    "        persist_data[(i, j)] = pickle.load(open(\"{}_X{}Y{}_persist.pkl\".format(\"Z16\", i, j), 'rb'))\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8,8))\n",
    "\n",
    "for (i, j) in persist_data:\n",
    "    persist = []\n",
    "\n",
    "    for pair in persist_data[(i, j)]:\n",
    "        if persist_data[(i, j)][pair] != np.inf:\n",
    "            persist.append(persist_data[(i, j)][pair])\n",
    "\n",
    "\n",
    "\n",
    "    sns.distplot(np.log10(persist), ax=ax, kde=False, norm_hist=True, \n",
    "                 hist_kws={\"cumulative\": True, \"histtype\": \"step\", \"linewidth\": 1, \"alpha\":1.0, \"color\": 'b'})\n",
    "    \n",
    "    \n",
    "persist_data = {}\n",
    "\n",
    "for i in range(1):\n",
    "    for j in range(1):\n",
    "\n",
    "        persist_data[(i, j)] = pickle.load(open(\"{}_X{}Y{}_persist.pkl\".format(\"Z8\", i, j), 'rb'))\n",
    "\n",
    "\n",
    "for (i, j) in persist_data:\n",
    "    persist = []\n",
    "\n",
    "    for pair in persist_data[(i, j)]:\n",
    "        if persist_data[(i, j)][pair] != np.inf:\n",
    "            persist.append(persist_data[(i, j)][pair])\n",
    "\n",
    "\n",
    "\n",
    "    sns.distplot(np.log10(persist), ax=ax, kde=False, norm_hist=True, \n",
    "                 hist_kws={\"cumulative\": True, \"histtype\": \"step\", \"linewidth\": 1, \"alpha\":1.0, \"color\": 'r'})\n",
    "    \n",
    "persist_data = {}\n",
    "\n",
    "for i in range(1):\n",
    "    for j in range(1):\n",
    "\n",
    "        persist_data[(i, j)] = pickle.load(open(\"{}_X{}Y{}_persist.pkl\".format(\"Z4\", i, j), 'rb'))\n",
    "\n",
    "\n",
    "for (i, j) in persist_data:\n",
    "    persist = []\n",
    "\n",
    "    for pair in persist_data[(i, j)]:\n",
    "        if persist_data[(i, j)][pair] != np.inf and persist_data[(i, j)][pair] != 0:\n",
    "            persist.append(persist_data[(i, j)][pair])\n",
    "\n",
    "\n",
    "\n",
    "    sns.distplot(np.log10(persist), ax=ax, kde=False, norm_hist=True, \n",
    "                 hist_kws={\"cumulative\": True, \"histtype\": \"step\", \"linewidth\": 1, \"alpha\":1.0, \"color\": 'g'})\n",
    "\n",
    "    \n",
    "persist_data = {}\n",
    "\n",
    "for i in range(1):\n",
    "    for j in range(1):\n",
    "\n",
    "        persist_data[(i, j)] = pickle.load(open(\"{}_X{}Y{}_persist.pkl\".format(\"Z1\", i, j), 'rb'))\n",
    "\n",
    "for (i, j) in persist_data:\n",
    "    persist = []\n",
    "\n",
    "    for pair in persist_data[(i, j)]:\n",
    "        if persist_data[(i, j)][pair] != np.inf and persist_data[(i, j)][pair] != 0:\n",
    "            persist.append(persist_data[(i, j)][pair])\n",
    "\n",
    "\n",
    "\n",
    "    sns.distplot(np.log10(persist), ax=ax, kde=False, norm_hist=True, \n",
    "                 hist_kws={\"cumulative\": True, \"histtype\": \"step\", \"linewidth\": 2, \"alpha\":1.0, \"color\": 'm'})\n",
    "\n",
    "ax.set_xlabel(r\"$\\log_{10}$Persistence\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import mixture, cluster, manifold\n",
    "\n",
    "P = []\n",
    "A = []\n",
    "\n",
    "for pi, (i, j) in enumerate(pairs):\n",
    "    \n",
    "    if j is not None and persistence[pi] > 0:\n",
    "        P.append(persistence[pi])\n",
    "        A.append(area[pi])\n",
    "\n",
    "X = np.log10(np.vstack((P, A)).T)\n",
    "\n",
    "n_clusters = 2\n",
    "\n",
    "print(\"Gaussian Mixture Model\")\n",
    "\n",
    "model = mixture.GaussianMixture(n_components=n_clusters, covariance_type='full')\n",
    "\n",
    "model.fit(X)\n",
    "print(model.bic(X))\n",
    "      \n",
    "Y = model.predict(X)\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(6,6))\n",
    "\n",
    "palette = it.cycle(sns.color_palette(\"deep\"))\n",
    "\n",
    "for i ,(mean, cov) in enumerate(zip(model.means_, model.covariances_)):\n",
    "    \n",
    "    color = next(palette)\n",
    "    \n",
    "    ax.scatter(X[Y == i, 0], X[Y == i, 1], marker='.', s=8, color=color)\n",
    "\n",
    "\n",
    "#     v, w = la.eigh(cov)\n",
    "#     angle = np.arctan2(w[0][1], w[0][0])\n",
    "#     angle = 180. * angle / np.pi  # convert to degrees\n",
    "#     v = 2. * np.sqrt(2.) * np.sqrt(v)\n",
    "#     ell = mpl.patches.Ellipse(mean, v[0], v[1], 180. + angle, color='k')\n",
    "#     ell.set_clip_box(ax.bbox)\n",
    "#     ell.set_alpha(.5)\n",
    "#     ax.add_artist(ell)\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"K-Mean Clustering\")\n",
    "\n",
    "model = cluster.KMeans(n_clusters=n_clusters)\n",
    "\n",
    "model.fit(X)\n",
    "      \n",
    "Y = model.predict(X)\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(6,6))\n",
    "\n",
    "palette = it.cycle(sns.color_palette(\"deep\"))\n",
    "\n",
    "for i , center in enumerate(model.cluster_centers_):\n",
    "    \n",
    "    color = next(palette)\n",
    "    \n",
    "    ax.scatter(X[Y == i, 0], X[Y == i, 1], marker='.', s=8, color=color)\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# print(\"Mean-Shift\")\n",
    "\n",
    "\n",
    "\n",
    "# model = cluster.MeanShift()\n",
    "\n",
    "# model.fit(X)\n",
    "      \n",
    "# Y = model.predict(X)\n",
    "\n",
    "# fig, ax = plt.subplots(1,1, figsize=(6,6))\n",
    "\n",
    "# palette = it.cycle(sns.color_palette(\"deep\"))\n",
    "\n",
    "# for i , center in enumerate(model.cluster_centers_):\n",
    "    \n",
    "#     color = next(palette)\n",
    "    \n",
    "#     ax.scatter(X[Y == i, 0], X[Y == i, 1], marker='.', s=8, color=color)\n",
    "\n",
    "\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
